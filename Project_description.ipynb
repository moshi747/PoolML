{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1222b72-2b79-4120-be3a-93fe5dd82247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pool\n",
    "import data\n",
    "import env\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191e612-8327-43ad-b448-a495d67eba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Rough outline:\n",
    "\n",
    "Introduction:\n",
    "    Background on pool\n",
    "    Goal of this project\n",
    "\n",
    "Vision\n",
    "    Showcase using a few pictures\n",
    "    Rough description on how the transform is done\n",
    "    \n",
    "Algorithm\n",
    "    Domain knowledge and feature engineering\n",
    "    Generating data\n",
    "    Models\n",
    "    Sample shots (show using the different models)\n",
    "    Performance analysis (how they do on average against random shots)\n",
    "        Baseline is random shot selection + constant shot selection\n",
    "\n",
    "Conclusion and future plans\n",
    "\n",
    "\n",
    "Functions to implement:\n",
    "    Generate random ball\n",
    "    Function that outputs the given strike (input is ball layout)\n",
    "        Input should include the feature function\n",
    "    Function that does viewing\n",
    "    Function that scores over random positions\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70e6b2-9e40-4fba-b5b3-c0f74d893269",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Background on pool\n",
    "\n",
    "In pool, a general goal is to use the cue ball (white ball) to pot an object ball (numbered ball) into a pocket. In many games, a critical part is to not only pot the object ball but to also leave the cue ball in a good position for the next shot (see https://en.wikipedia.org/wiki/Nine-ball). This is called *playing position* and can be achieved by varying the three scalars below:\n",
    "\n",
    "speed, horizontal strike position (x-strike), vertical strike position (y-strike)\n",
    "\n",
    "# Goal of this project\n",
    "\n",
    "The goal is to use machine learning to approximate the following function\n",
    "\n",
    "$$f(\\text{position of the balls (cue ball + object balls)})= \\text{speed, x-strike, y-strike}$$\n",
    "\n",
    "which outputs the best way to hit the cue ball to play position given the current layout of the balls. As most experienced pool players know, pool is a game of milimeters meaning the slightest of change is the layout of the balls can have a big impact on how you would play. Hence the ideal function $f$ would be very complex, expecially if there are many object balls.\n",
    "\n",
    "We will rely on an open source pool simulator (https://ekiefl.github.io/projects/pooltool/) developed by Evan Kiefl.\n",
    "\n",
    "There will be two parts. The first part is to use computer vision to analyze a picture of a pool table taken by the user. The algorithm will then detect the playing surface of the table along with the location of the balls. The pool balls will be detected using a fine-tuned model of YOLO-V8. The second part is creating a ML model that learns the function $f$.\n",
    "\n",
    "# Detecting ball locations from a picture\n",
    "\n",
    "Our first task is to determine the playing surface of the table. Since pool cloth usually have two common colors (green or blue), we use simple masking to find a large area where the color is constant. We will use the following image for demonstration purposes.\n",
    "\n",
    "![table](Vision/mytable3.jpeg)\n",
    "\n",
    "In order to detect edges, we first mask the image for colors close to that of the cloth (blue in this case). There are other blue objects in this image, but we will filter them out by only considering the region with the largest area. Then we apply a Hough transform which detects the edges of the playing region. The detected edges of the playing surface are shown using red lines here\n",
    "\n",
    "![table](Vision/mytable3lines.jpeg)\n",
    "\n",
    "In a separate process, the fine-tuned YOLO-V8 model detects balls on the table as shown here\n",
    "\n",
    "![table](Vision/mytable3pred.jpg)\n",
    "\n",
    "Note it misclassifies a ball outside of the table although to a low confidence level. For our purposes this is okay since as long as the misclassified object is not on the playing surface, the object will not be considered after we do a transformation. In the last step we compute the holography which lays the playing region flat. The resulting coordinates of the balls are then given as output to be used for the pool AI.\n",
    "\n",
    "![table](Vision/mytable3warp_pred.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09586ca-4253-4310-8aa8-3c70c8fa6981",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100f98b3-8907-41a3-a5cc-416b0fd40038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = xgb.XGBRegressor(n_estimators = 4000)\n",
    "tree.load_model('boostedLarge.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14c6571-1ddc-4593-8714-82361f33672e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Known pipe types:\n",
      "  CocoaGraphicsPipe\n",
      "(all display modules loaded.)\n",
      ":interval(warning): CLerpNodePathInterval::priv_step() called for LerpPosQuatInterval-743 in state final.\n",
      ":interval(warning): CLerpNodePathInterval::priv_step() called for LerpPosInterval-744 in state final.\n",
      ":interval(warning): CLerpNodePathInterval::priv_step() called for LerpPosQuatInterval-791 in state final.\n",
      ":interval(warning): CLerpNodePathInterval::priv_step() called for LerpPosInterval-792 in state final.\n"
     ]
    }
   ],
   "source": [
    "poolai = pool.PoolAI(tree, features=[pool.positions(['2'])], output='hit', hit_scale='raw')\n",
    "\n",
    "pool.view_shots(poolai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f121f7-f674-4b2b-bdb4-f6926ebb1cd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating a model for $f$ \n",
    "\n",
    "\n",
    "### Simplest case\n",
    "\n",
    "For now, we will consider the simplest case of when there are two object balls. In order for the AI to learn how effective a particular shot was, we need a way to value the result (the location of the cue ball and the remaining object ball after potting). While this can probably be done by some geometric calculation, we will use a DNN to achieve this.\n",
    "\n",
    "### Creating a DNN for valuating shots\n",
    "\n",
    "We use supervised learning. Our data will consist of the position of the cue ball and object ball together with $0\\leq n\\leq 1$ which measures the difficulty of the shot ($0$ being most difficult and $1$ being easiest).\n",
    "\n",
    "So there are $4$ feature cue-x, cue-y, one-x, one-y for the $xy$-coordinates of the balls and one output $n$. To construct the data, we generate the positions of the balls randomly and simulate $100$ shots where we slightly adjust the aiming point every time. The ratio of times we pot the object ball will be our $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542b605d-9cf6-43ad-964e-dc04f0fa556e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data import generate_data\n",
    "\n",
    "one_ball_data = generate_data(10000, tests=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfd3d9-2896-45b3-b51a-b619e99168c3",
   "metadata": {},
   "source": [
    "Once enough data has been generated, we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6386e4-d753-46d1-81be-5e5d3b99be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression import train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(one_ball_data.iloc[:,:-1], one_ball_data.iloc[:,-1:])\n",
    "\n",
    "reg_net, train_losses, test_losses = train(X_train, X_test, y_train, y_test,\n",
    "                                           hidden_sizes = [128, 128, 128], epochs = 10000, lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6872-116c-4afe-87c1-53f679376113",
   "metadata": {},
   "source": [
    "Let's visualize the CV scores to see how the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b6032-06e1-4d4f-b2d8-bf07ecaef3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add plot here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "\n",
    "plt.plot(np.arange(len(train_losses)), train_losses, label='train loss')\n",
    "\n",
    "plt.plot(np.arange(len(test_losses)), test_losses, label='test loss')\n",
    "\n",
    "ax = fig.axes[0]\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8922917-566f-4cd1-89eb-410115778581",
   "metadata": {},
   "source": [
    "Now that we have a baseline model for valuating the resulting position, let's move on to the next step of our original goal.\n",
    "\n",
    "### Two methods\n",
    "\n",
    "We present two different methods for constructing a model\n",
    "\n",
    "* Supervised learning\n",
    "\n",
    "* Reinforcement learning\n",
    "\n",
    "In both cases, the goal is to learn the following function\n",
    "\n",
    "$$Q (\\text{cue-x, cue-y, one-x, one-y, two-x, two-y, speed, x-spin, y-spin}) = n\\in [0,100]$$\n",
    "\n",
    "which is defined as valuating the resulting position from shooting the cue ball in the given way potting the one ball. In reinforcement learning, the algorithm will also output a policy function which takes input the positions of the balls and outputs the hit on the cue ball that results in the highest output of the $Q$-function.\n",
    "\n",
    "Let us now go into the details for each one\n",
    "\n",
    "### Supervised learning model\n",
    "\n",
    "In this case, our goal again is to construct a bunch of data by randomly generating points in the domain of $Q$ and logging its output. This is done using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484feadd-7d49-4bbf-9484-714f1850d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import generate_position_data\n",
    "\n",
    "two_ball_data = generate_position_data(2000, reg_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d7132-d489-4618-9876-6ff4ae1b23cb",
   "metadata": {},
   "source": [
    "We then use the same code as before to train a DNN on this data. The performance is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753f7d8-c8cf-4a00-89fd-99868cbccfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate performance here\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(two_ball_data.iloc[:,:-1], two_ball_data.iloc[:,-1:])\n",
    "\n",
    "reg_net_2, train_losses, test_losses = train(X_train, X_test, y_train, y_test,\n",
    "                                             hidden_sizes = [128, 128, 128, 128], epochs = 10000, lr = 0.001)\n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "\n",
    "plt.plot(np.arange(len(train_losses)), train_losses, label='train loss')\n",
    "\n",
    "plt.plot(np.arange(len(test_losses)), test_losses, label='test loss')\n",
    "\n",
    "ax = fig.axes[0]\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69370a87-3d42-4769-a45b-69f6283030ac",
   "metadata": {},
   "source": [
    "The MSE here is higher than the case with a single object ball. The function we're trying to learn here is much more intricate. We also tried XGBoost, but the results were not as goot as the neural network.\n",
    "\n",
    "### Reinforcement learning model\n",
    "\n",
    "Here we created a GYM API for this task. The natural choices for the states are the position of the balls and the transition actions are given by the hit on the cue ball. The interesting part is setting up the reward function for the actions. We settled on the following\n",
    "\n",
    "1. If object ball is not potted:\n",
    "\n",
    "    a. If no object ball moves: $-10$\n",
    "    \n",
    "    b. Else: $-0.1$\n",
    "    \n",
    "2. Elif cue ball scratches (goes into a pocket): $-4$\n",
    "\n",
    "3. Elif both object balls are potted: $0$\n",
    "\n",
    "4. Else (target object ball potted and two balls remain on the table): $4(e^{n/100}-1)$ where $n$ is the valuation of the resulting position.\n",
    "\n",
    "The reason we chose to include an exponential function in the last case is to emphasize the importance of getting as close to the largest $n$ as possible by offering a reward that is weighted exponentially rather than linealry on $n$. This seem to work well in practice as our experiments showed. The exact algorithm we employ is the soft actor-critic method given here https://spinningup.openai.com/en/latest/algorithms/sac.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b5547-91ef-43b2-b028-efd63b47b47f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spinup.algos.pytorch.sac.sac import sac\n",
    "from env import Pool_random\n",
    "\n",
    "sac(Pool_random, epochs = 10, alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3add3-0ad6-46c3-bde9-48f52f773d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a69bfa21-ed1e-474f-bbdc-f64bce6db7c4",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now that we have the case of two balls finished, we can move on to 3, 4, ..., and eventually 9 balls for the game of 9-ball. The inductive step is as follows: Once we have a model for $n$ many balls, we can use our model to construct an auxilary model which learns the *value function* attached to any layout of $n$ balls. This value function can be thought of as the maximum possible reward attainable by following the optimal shooting choices (which we have a model for). Then we may construct a model for $n+1$ balls by either supervised or reinforcement learning as before trying to maximize the value function of the remaining layout after potting.\n",
    "\n",
    "Another approach would be to simply apply a reinforcement or supervised learning algorithm to the case of 9 balls. In practice, we found the complexity coming from the number of balls makes it very hard to optimize the model. Hence, we are taking an iterative approach as shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d51574-f1b6-40ac-be3b-21607d077472",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "While a random layout of 9 balls seemed too much for reinforcement learning to optimize, having a fixed starting layout is much easier. Here we demonstrate using the GYM environemnt Pool_static which takes as input a fixed starting layout of balls and always starts here whenever reset is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c7afb-a520-485a-9fba-6c75a6f8a125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from env import Pool_static\n",
    "\n",
    "sac(Pool_random, epochs = 10, alpha = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2f029-bc0a-4e58-913d-dce6465e7798",
   "metadata": {},
   "source": [
    "Here is a video demonstrating the shots learned for a particular layout of 9-ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9c05a-2b43-4bbe-8347-1dc744433bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
